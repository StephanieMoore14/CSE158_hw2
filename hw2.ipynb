{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy\n",
    "import urllib\n",
    "import random\n",
    "import ast\n",
    "\n",
    "# import warnings filter\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "* Polish Bankruptcy data : https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks — Diagnostics (week 2):\n",
    "In the first homework, we had two issues with the classifiers we built. Namely (1) the data were not shuffled, and (2) the labels were highly imbalanced. Both of these made it difficult to effectively build an accurate classifier. Here we’ll try and correct for those issues using the Bankruptcy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Download and parse the bankruptcy data. We’ll use the 5year.arff file. Code to read the data is\n",
    "available in the stub.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline(): # filter past odd lines\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_bank(file): \n",
    "    dataset = []\n",
    "    for l in file:\n",
    "        if '?' in l: # Missing entry\n",
    "            continue\n",
    "        l = l.split(',')\n",
    "        values = [1] + [float(x) for x in l]\n",
    "        values[-1] = values[-1] > 0 # Convert to bool\n",
    "        dataset.append(values)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_bank(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a logistic regressor (e.g. sklearn.linear model.LogisticRegression) with\n",
    "regularization coefficient C = 1.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I've created a helper function to calculate the BER for predictions and labels based on the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_BER(predictions, y_true):\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y_true)])\n",
    "    FP = sum([(p and not l) for (p,l) in zip(predictions, y_true)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y_true)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(predictions, y_true)])\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    BER = 1 - 1/2 * (TPR + TNR)\n",
    "    return BER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This helper function calculates the accuracy of a model given the data of features for prediction, the true labels, and the type of data set it is: Training, Validation, or Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_BER(mod, X, labels, test=''):\n",
    "    pred = mod.predict(X)\n",
    "    correctPred = [1 if pred[i]  == labels[i] else 0 for i in range(len(pred))]\n",
    "    accur = sum(correctPred) / len(correctPred)\n",
    "    ber = calc_BER(pred, labels)\n",
    "    return [accur, ber]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is purely a funciton that makes answers that only have a few values easier to read, since they are not being formatted in a huge dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(ls, test):\n",
    "    accur = ls[0]\n",
    "    ber = ls[1]\n",
    "    print(\"{} Accuracy = \".format(test) + str(accur))\n",
    "    print(\"{} Balanced Error Rate = \".format(test) + str(ber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report the accuracy and Balanced Error Rate (BER) of your classifier (1 mark).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy = 0.9660178159023425\n",
      " Balanced Error Rate = 0.4859769445504388\n"
     ]
    }
   ],
   "source": [
    "format_results(calc_accuracy_BER(model, X, y), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (CSE158 only) Retrain the above model using the class weight=’balanced’ option. Report the\n",
    "accuracy and BER of your new classifier (1 mark).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_model = linear_model.LogisticRegression(class_weight='balanced')\n",
    "bal_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy = 0.7845595513032002\n",
      " Balanced Error Rate = 0.20609657314615837\n"
     ]
    }
   ],
   "source": [
    "format_results(calc_accuracy_BER(bal_model, X, y), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Shuffle the data, and split it into training, validation, and test splits, with a 50/ 25/ 25% ratio. Using the class weight=’balanced’ option, and training on the training set, report the training/validation/test accuracy and BER (1 mark).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline(): # filter past odd lines\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_bank(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "N = len(X)\n",
    "fifty = int(np.around(N*.5))\n",
    "seventy_five = int(np.around(N*.75))\n",
    "\n",
    "X_train = X[:fifty]\n",
    "X_valid = X[fifty:seventy_five]\n",
    "X_test = X[seventy_five:]\n",
    "\n",
    "y_train = y[:fifty]\n",
    "y_valid = y[fifty:seventy_five]\n",
    "y_test = y[seventy_five:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on training set\n",
    "random_model = linear_model.LogisticRegression(class_weight='balanced')\n",
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.8410290237467019\n",
      "Training Balanced Error Rate = 0.2159016844575119\n"
     ]
    }
   ],
   "source": [
    "# Training Set Results\n",
    "format_results(calc_accuracy_BER(random_model, X_train, y_train), 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 0.8348745046235139\n",
      "Validation Balanced Error Rate = 0.2236995341614907\n"
     ]
    }
   ],
   "source": [
    "# Validation Set Results\n",
    "format_results(calc_accuracy_BER(random_model, X_valid, y_valid), 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy = 0.8390501319261213\n",
      "Testing Balanced Error Rate = 0.23842216444588882\n"
     ]
    }
   ],
   "source": [
    "# Testing Set Results\n",
    "format_results(calc_accuracy_BER(random_model, X_test, y_test), 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Implement a complete regularization pipeline with the balanced classifier. Consider values of C in the range {10^-4, 10^-3, . . . , 10^3, 10^4}. Report (or plot) the train, validation, and test BER for each value of C.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline(): # filter past odd lines\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload and reshuffle\n",
    "\n",
    "dataset = download_bank(f)\n",
    "random.shuffle(dataset)\n",
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]\n",
    "\n",
    "# split the data\n",
    "N = len(X)\n",
    "fifty = int(np.around(N*.5))\n",
    "seventy_five = int(np.around(N*.75))\n",
    "\n",
    "X_train = X[:fifty]\n",
    "X_valid = X[fifty:seventy_five]\n",
    "X_test = X[seventy_five:]\n",
    "\n",
    "y_train = y[:fifty]\n",
    "y_valid = y[fifty:seventy_five]\n",
    "y_test = y[seventy_five:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C values: {10^-4, 10^-3, . . . , 10^3, 10^4}\n",
    "\n",
    "c_model = [10**i for i in range(-4, 5)]\n",
    "c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.96012e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "train_BER = []\n",
    "valid_BER = []\n",
    "test_BER = []\n",
    "\n",
    "# to find BER, I need to compare the actual labels with the predicted labels \n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "for mod in c_model:        \n",
    "    reg_model = RidgeClassifier(mod, class_weight='balanced', fit_intercept=False)\n",
    "    reg_model.fit(X_train, y_train)\n",
    "    \n",
    "    tr = calc_accuracy_BER(reg_model, X_train, y_train, 'Training')\n",
    "    val = calc_accuracy_BER(reg_model, X_valid, y_valid, 'Validation')\n",
    "    te = calc_accuracy_BER(reg_model, X_test, y_test, 'Testing')\n",
    "    \n",
    "    train_BER.append(tr[1])    \n",
    "    valid_BER.append(val[1]) \n",
    "    test_BER.append(te[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training BER</th>\n",
       "      <th>Validation BER</th>\n",
       "      <th>Testing BER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C Values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.112660</td>\n",
       "      <td>0.216098</td>\n",
       "      <td>0.199506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.112999</td>\n",
       "      <td>0.215409</td>\n",
       "      <td>0.200189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.112999</td>\n",
       "      <td>0.199280</td>\n",
       "      <td>0.198823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.113679</td>\n",
       "      <td>0.179708</td>\n",
       "      <td>0.198823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.115039</td>\n",
       "      <td>0.195837</td>\n",
       "      <td>0.175494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.143719</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.165143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.174545</td>\n",
       "      <td>0.225451</td>\n",
       "      <td>0.229561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.225659</td>\n",
       "      <td>0.229294</td>\n",
       "      <td>0.177911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0000</th>\n",
       "      <td>0.258313</td>\n",
       "      <td>0.264307</td>\n",
       "      <td>0.199874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Training BER  Validation BER  Testing BER\n",
       "C Values                                             \n",
       "0.0001          0.112660        0.216098     0.199506\n",
       "0.0010          0.112999        0.215409     0.200189\n",
       "0.0100          0.112999        0.199280     0.198823\n",
       "0.1000          0.113679        0.179708     0.198823\n",
       "1.0000          0.115039        0.195837     0.175494\n",
       "10.0000         0.143719        0.185906     0.165143\n",
       "100.0000        0.174545        0.225451     0.229561\n",
       "1000.0000       0.225659        0.229294     0.177911\n",
       "10000.0000      0.258313        0.264307     0.199874"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Training BER': train_BER, 'Validation BER': valid_BER,'Testing BER': test_BER})\n",
    "df.index = c_model\n",
    "df = df.rename_axis('C Values')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on these values, which classifier would you select (in terms of  generalization performance) and why (1 mark)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which value of C we should use with our model on unseen data, we need to look at the performance of each C Value on the data in the validation set (performance here measured by BER (Balanced Error Rate)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_validation_BER = df['Validation BER'].idxmin()\n",
    "min_validation_BER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a C Value of 0.1 yields the lowest BER on the validation set. The plot also below helps show the starting point (C = 0.1) is the lowest BER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When I reshuffled the data a few times, the \"best\" C value alternated between the lower values of C (between C = .001 and C = 100). It is important to note that the way the data is shuffled can affect the answer for what the \"best\" value of C is. However, the larger values for C (i.e. 1000, 10000) didnt produce a low BER for any of the time I shuffled the data. This artifact of the data is reflected in the plot above (and was confirmed in the plots of other shuffled data results). The C values before the 2000 mark show some fluctuation in the BER score, but after that it is mostle constantly increasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. (CSE158 only) Compute the Fβ scores for β = 1, β = 0.1, and β = 10 for the above classifier, using\n",
    "C = 1 (on the test set) (1 mark).**\n",
    "<table><tr><td><img src=\"imgs/F_b_score.png\"></td><td><img src=\"imgs/prec_recall.png\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline(): # filter past odd lines\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_bank(f)\n",
    "\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]\n",
    "\n",
    "# split the data\n",
    "N = len(X)\n",
    "fifty = int(np.around(N*.5))\n",
    "seventy_five = int(np.around(N*.75))\n",
    "\n",
    "X_train = X[:fifty]\n",
    "X_valid = X[fifty:seventy_five]\n",
    "X_test = X[seventy_five:]\n",
    "\n",
    "y_train = y[:fifty]\n",
    "y_valid = y[fifty:seventy_five]\n",
    "y_test = y[seventy_five:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args: (y_true, y_pred)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_bscore(prec, rec, b):\n",
    "    return (1 + b**2) * ((prec * rec) / ((b**2 * prec) + rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the Testing Set, the Fβ score is calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>β = 1</th>\n",
       "      <th>β = 0.01</th>\n",
       "      <th>β = 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fβ Score</th>\n",
       "      <td>0.231156</td>\n",
       "      <td>0.134846</td>\n",
       "      <td>0.808844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             β = 1  β = 0.01    β = 10\n",
       "Fβ Score  0.231156  0.134846  0.808844"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "b_list = [1, 0.1, 10]\n",
    "for b in b_list:\n",
    "    precision = precision_score(y_test, predictions) \n",
    "    recall = recall_score(y_test, predictions)\n",
    "    scores.append(F_bscore(precision, recall, b))\n",
    "    \n",
    "df = pd.DataFrame({'β = 1': [scores[0]], 'β = 0.01': [scores[1]], 'β = 10': [scores[2]]})\n",
    "df.index = ['Fβ Score']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks — Dimensionality Reduction (week 3):\n",
    "Next we’ll consider using PCA to build a lower-dimensional feature vector to do prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Following the stub code, compute the PCA basis on the training set. Report the first PCA component\n",
    "(i.e., pca.components_[0]) (1 mark).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not '@data' in f.readline(): # filter past odd lines\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_bank(f)\n",
    "\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]\n",
    "\n",
    "# split the data\n",
    "N = len(X)\n",
    "fifty = int(np.around(N*.5))\n",
    "seventy_five = int(np.around(N*.75))\n",
    "\n",
    "X_train = X[:fifty]\n",
    "X_valid = X[fifty:seventy_five]\n",
    "X_test = X[seventy_five:]\n",
    "\n",
    "y_train = y[:fifty]\n",
    "y_valid = y[fifty:seventy_five]\n",
    "y_test = y[seventy_five:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # PCA library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=65, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(X_train[0]) # extract all features\n",
    "pca = PCA(n_components = n) \n",
    "pca.fit(X_train) # computes covarience matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first PCA component is shown below. This is the eivenvectors of the basis that describes all features of the training data (since we extracted all the features) in order of eigenvalue, increasing by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.72366413e-18, -7.96886398e-08,  3.91014929e-07,  1.11279754e-06,\n",
       "        5.16667884e-06,  2.78916853e-03, -7.49568382e-07,  1.90082849e-06,\n",
       "        6.27019137e-06, -1.01100433e-06, -1.64752592e-07,  2.35569473e-07,\n",
       "        1.35245326e-06, -6.82370062e-06,  1.90036111e-06, -4.06995993e-04,\n",
       "        8.60036434e-07,  6.80892851e-06,  1.72858080e-06,  5.46735386e-07,\n",
       "        2.99039874e-05, -1.20289660e-07,  2.25196723e-07,  4.95199103e-07,\n",
       "        8.84159465e-07,  7.76555544e-07,  7.78796412e-07, -1.15899837e-04,\n",
       "        1.94249727e-06,  4.82950151e-06, -2.13729773e-06,  5.22896972e-07,\n",
       "       -5.09301352e-04,  5.19872173e-06, -2.84545331e-06,  1.97850712e-07,\n",
       "       -1.15035841e-06,  1.13187107e-03, -6.82727802e-07,  1.74804872e-07,\n",
       "        2.71420122e-06, -3.43963110e-06,  3.27610269e-07,  2.95458611e-05,\n",
       "       -3.62967208e-07, -1.43794759e-06,  4.12005757e-06, -9.63444238e-05,\n",
       "        2.90798241e-07,  5.12485806e-07,  4.68138138e-06, -8.69021852e-07,\n",
       "       -1.35724399e-06, -4.33884092e-06,  2.04207565e-06,  9.99995191e-01,\n",
       "        2.07380213e-07, -6.18703290e-07, -3.03031270e-07,  4.94394301e-07,\n",
       "       -1.77436616e-04, -1.44371281e-05, -2.75137808e-04,  6.64450308e-06,\n",
       "       -1.81247104e-05])"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Next we’ll train a model using a low-dimensional feature vector. By representing the data in the above\n",
    "basis, i.e.:**\n",
    "\n",
    "Xpca_train = numpy.matmul(Xtrain, pca.components_.T)\n",
    "\n",
    "Xpca_valid = numpy.matmul(Xvalid, pca.components_.T)\n",
    "\n",
    "Xpca_test = numpy.matmul(Xtest, pca.components_.T)\n",
    "\n",
    "**compute the validation and test BER of a model that uses just the first N components (i.e., dimensions) for N = 5, 10, . . . , 25, 30. Again use class weight=’balanced’ and C = 1.0 (2 marks).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformed (rotated) dataset\n",
    "\n",
    "Xpca_train = numpy.matmul(X_train, pca.components_.T)\n",
    "Xpca_valid = numpy.matmul(X_valid, pca.components_.T)\n",
    "Xpca_test = numpy.matmul(X_test, pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\steph\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "dim = [i for i in range(5, 35, 5)]\n",
    "results = {'Validation BER': [], 'Testing BER': []}\n",
    "\n",
    "for d in dim:\n",
    "    # train a model on reduced data\n",
    "    mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "    reduced_train = [x[:d] for x in Xpca_train]\n",
    "    mod.fit(reduced_train, y_train)\n",
    "\n",
    "    reduced_val = [x[:d] for x in Xpca_valid]\n",
    "    reduced_test = [x[:d] for x in Xpca_test]\n",
    "    \n",
    "    val = mod.predict(reduced_val)\n",
    "    test = mod.predict(reduced_test)\n",
    "    \n",
    "    val_ = calc_BER(val, y_valid) # pred, true\n",
    "    test_ = calc_BER(test, y_test)\n",
    "    \n",
    "    results['Validation BER'] = results['Validation BER'] + [val_]\n",
    "    results['Testing BER'] = results['Testing BER'] + [test_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation BER</th>\n",
       "      <th>Testing BER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N Components</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.377104</td>\n",
       "      <td>0.254699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.336311</td>\n",
       "      <td>0.267214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.233546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.344508</td>\n",
       "      <td>0.252115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.296803</td>\n",
       "      <td>0.163627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.280902</td>\n",
       "      <td>0.160891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Validation BER  Testing BER\n",
       "N Components                             \n",
       "5                   0.377104     0.254699\n",
       "10                  0.336311     0.267214\n",
       "15                  0.376120     0.233546\n",
       "20                  0.344508     0.252115\n",
       "25                  0.296803     0.163627\n",
       "30                  0.280902     0.160891"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.index = dim\n",
    "df = df.rename_axis('N Components')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows us that as we increase the number of components of the basis we use, the BER decreases (for validation and testing sets). This makes sense because PCA trys to compress the data into a fewer number of the \"useful\" dimensions. So the more \"useful\" dimensions you use for prediction, the more accurate your predictions will be. Obviously, using all dimension will be the most \"useful\" as far as BER scores go, but the point is to try and make the problem less complex. Choosing the model you for the problem you are solving depends on the right balance you want/ can afford (space and time complexity) between too many dimensions and too low of a accuracy score (whichever form you use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
